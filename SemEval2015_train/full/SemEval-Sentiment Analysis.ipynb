{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 9665 rows, 4 columns\n",
      "                   id   tweet-id             sentiment  \\\n",
      "0  264183816548130816   15140428              positive   \n",
      "1  263405084770172928  591166521              negative   \n",
      "2  262163168678248449   35266263              negative   \n",
      "3  264249301910310912   18516728              negative   \n",
      "4  262682041215234048  254373818  objective-OR-neutral   \n",
      "\n",
      "                                                text  \n",
      "0  Gas by my house hit $3.39!!!! I'm going to Cha...  \n",
      "1                                      Not Available  \n",
      "2                                      Not Available  \n",
      "3  Iranian general says Israel's Iron Dome can't ...  \n",
      "4                                      Not Available  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"downloaded2.tsv\", sep = '\\t')\n",
    "print \"Dataset has {} rows, {} columns\".format(*data.shape)\n",
    "print data.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              sentiment                                               text\n",
      "0              positive  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1              negative                                      Not Available\n",
      "2              negative                                      Not Available\n",
      "3              negative  Iranian general says Israel's Iron Dome can't ...\n",
      "4  objective-OR-neutral                                      Not Available\n"
     ]
    }
   ],
   "source": [
    "#Let's drop the id-columns, they were used to download the twitter data, with twitter API.\n",
    "df = data.drop(data.columns[[0,1]], axis=1)\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment                                               text\n",
      "0  positive  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1  negative  Iranian general says Israel's Iron Dome can't ...\n",
      "2  positive  with J Davlar 11th. Main rivals are team Polan...\n",
      "3  negative  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "4  negative  They may have a SuperBowl in Dallas, but Dalla...\n",
      "Dataset has 7549 rows, 2 columns\n",
      "               sentiment                                               text\n",
      "0               positive  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1               negative  Iranian general says Israel's Iron Dome can't ...\n",
      "2               positive  with J Davlar 11th. Main rivals are team Polan...\n",
      "3               negative  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "4               negative  They may have a SuperBowl in Dallas, but Dalla...\n",
      "5                neutral  Im bringing the monster load of candy tomorrow...\n",
      "6   objective-OR-neutral  Apple software, retail chiefs out in overhaul:...\n",
      "7               positive  @oluoch @victor_otti @kunjand I just watched i...\n",
      "8              objective  #Livewire Nadal confirmed for Mexican Open in ...\n",
      "9               positive  @MsSheLahY I didnt want to just pop up... but ...\n",
      "10               neutral  @Alyoup005 @addicted2haley hmmmm  November is ...\n",
      "11             objective  #Iran US delisting MKO from global terrorists ...\n",
      "12              positive  Good Morning Becky ! Thursday is going to be F...\n",
      "13             objective  Expect light-moderate rains over E. Visayas; C...\n",
      "14              positive  One ticket left for the @49ers game tomorrow! ...\n",
      "15              negative  AFC away fans on Saturday. All this stuff abou...\n",
      "16              negative  Why is it so hard to find the @TVGuideMagazine...\n",
      "17  objective-OR-neutral  Game 1 of the NLCS and a rematch of the NFC Ch...\n",
      "18               neutral  @TrevorJavier the heat game may cost alot more...\n",
      "19              positive  Never start working on your dreams and goals t...\n"
     ]
    }
   ],
   "source": [
    "#Now let's drop all the rows in which the tweet was no longer available.\n",
    "df = df[df.text != \"Not Available\"]\n",
    "df = df.reset_index(drop=True) #reset the index after dropping the above rows\n",
    "print df.head()\n",
    "print \"Dataset has {} rows, {} columns\".format(*df.shape)\n",
    "print df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sentiment                                               text\n",
      "0           1  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1          -1  Iranian general says Israel's Iron Dome can't ...\n",
      "2           1  with J Davlar 11th. Main rivals are team Polan...\n",
      "3          -1  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "4          -1  They may have a SuperBowl in Dallas, but Dalla...\n",
      "5           0  Im bringing the monster load of candy tomorrow...\n",
      "6           0  Apple software, retail chiefs out in overhaul:...\n",
      "7           1  @oluoch @victor_otti @kunjand I just watched i...\n",
      "8           0  #Livewire Nadal confirmed for Mexican Open in ...\n",
      "9           1  @MsSheLahY I didnt want to just pop up... but ...\n",
      "10          0  @Alyoup005 @addicted2haley hmmmm  November is ...\n",
      "11          0  #Iran US delisting MKO from global terrorists ...\n",
      "12          1  Good Morning Becky ! Thursday is going to be F...\n",
      "13          0  Expect light-moderate rains over E. Visayas; C...\n",
      "14          1  One ticket left for the @49ers game tomorrow! ...\n",
      "15         -1  AFC away fans on Saturday. All this stuff abou...\n",
      "16         -1  Why is it so hard to find the @TVGuideMagazine...\n",
      "17          0  Game 1 of the NLCS and a rematch of the NFC Ch...\n",
      "18          0  @TrevorJavier the heat game may cost alot more...\n",
      "19          1  Never start working on your dreams and goals t...\n"
     ]
    }
   ],
   "source": [
    "#Next we need to re-write the neutral / objective labels to all be neutral.  The organizers kept this distinction\n",
    "#for other tasks, but for this task, it's considered the same.\n",
    "# so, let's re-write all objective ->neutral, and all neutral-OR-objective --> neutral.\n",
    "\n",
    "#Since we probably will want our labels numeric (some classifiers may not like 3-way text labels),\n",
    "#we can do that all now.\n",
    "\n",
    "df = df.apply(lambda x: x.replace(['positive', 'negative', 'neutral', 'objective', 'objective-OR-neutral']\n",
    "                                  , [1, -1,0,0,0]) ,1)\n",
    "print df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is : 7549\n",
      "There are 2820 positive tweets or 0.373559411843%\n",
      "There are 1066 Negative tweets or 0.141210756392%\n",
      "There are 3663 Neutral tweets or 0.485229831766%\n"
     ]
    }
   ],
   "source": [
    "#Let's take a look at our class distribution\n",
    "total_tweets = len(df)\n",
    "positive_tweets = sum(df.sentiment == 1)\n",
    "negative_tweets = sum(df.sentiment == -1)\n",
    "neutral_tweets = sum(df.sentiment == 0)\n",
    "\n",
    "print \"The total number of samples is : {}\".format(len(df.sentiment))\n",
    "print \"There are {} positive tweets or {}%\".format \\\n",
    "(positive_tweets, positive_tweets/float(total_tweets) )\n",
    "print \"There are {} Negative tweets or {}%\".format \\\n",
    "(negative_tweets, negative_tweets / float(total_tweets))\n",
    "print \"There are {} Neutral tweets or {}%\".format \\\n",
    "(neutral_tweets, neutral_tweets/ float(total_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gas', 'by', 'my', 'house', 'hit', '$3.39!!!!', \"I'm\", 'going', 'to', 'Chapel', 'Hill', 'on', 'Sat.', ':)']\n"
     ]
    }
   ],
   "source": [
    "# Let's load the texts into lists and remove RT's and URls\n",
    "# we will build a custom function for an individual tweet, \n",
    "#and then use Pandas Dataframe.apply() to run it on all tweets.\n",
    "\n",
    "first_tweet = \"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\"\n",
    "def parse_tweet (text):\n",
    "    text = text.split()\n",
    "    return text\n",
    "    \n",
    "parsed_tweet = parse_tweet(first_tweet)\n",
    "print parsed_tweet\n",
    "#this results in the most basic splitting operation.  However it gets us very close to what we want.\n",
    "#In the below output the only concern I have is with \"!!!!\" attached to \"$3.39\".  This is not really ideal.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gas', 'by', 'my', 'house', 'hit', '$3.39', '!', '!', '!', '!', \"I'm\", 'going', 'to', 'Chapel', 'Hill', 'on', 'Sat', '.', ':)']\n",
      "['Cool', '#cdnpoli', 'Call', 'the', 'hospital', 'in', 'Iqaluit', '&amp;', 'press', '2', 'for', 'English', '.', 'Experience', 'an', 'aboriginal', 'language', 'as', '1st', 'choice']\n",
      "['For', 'how', 'long,', 'i', 'might', 'be', 'in', 'NJ', 'then', '?', '@blove402', 'Thursday', 'Night', 'the', '13th', 'of', 'Dec', '.']\n",
      "['Get', 'ready', 'for', 'our', 'Wednesday', 'Drink', 'Specials', 'Wednesday', '-', '3-8pm', 'Have', 'it', 'your', 'Way', 'Margarita', 'Day', '(', 'Bar', 'Brand', 'Only)', 'DOTDOTDOT']\n"
     ]
    }
   ],
   "source": [
    "#Let's enhance the parser to deal with a few more special cases\n",
    "\n",
    "#compile regex outside of the function, because we will be running this function in a loop.\n",
    "retweets = re.compile(r'(RT ?@.*:)')   \n",
    "urls = re.compile(r'(http:.*\\b)')\n",
    "dotdotdot = re.compile(r'(\\.\\.\\.)')\n",
    "pound_question = re.compile(r'([!\\?])')\n",
    "period_dot = re.compile(r'(\\.(?!\\d))')\n",
    "\n",
    "regex_args = (retweets, urls, dotdotdot, pound_question, period_dot)\n",
    "\n",
    "\n",
    "def parse_tweet (text , retweets, urls, dotdotdot, pound_question, period_dot):\n",
    "    text = re.sub(retweets, \"\", text) #removes RT@thisguy: or RT @thisguy:   two common Retweet bits I dont' need\n",
    "    text = re.sub(urls, \"\", text) # removes URL's\n",
    "    text = re.sub(dotdotdot, ' DOTDOTDOT', text) #replace '...' with \"DOTDOTDOT' so i preserve the meaning in that token\n",
    "    text = re.sub(pound_question, r' \\1 ', text)  #eyes bleeding? Searches for ! ? and adds white space around them.\n",
    "    text = re.sub(period_dot, r' \\1 ', text) #more blood.  searched for '.' but looks ahead for digits. will not break 3.39\n",
    "  \n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "\n",
    "############\n",
    "#Test cases#\n",
    "############\n",
    "first_tweet = \"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\"\n",
    "RT_tweet_1 = \"Cool #cdnpoli RT@angelpike: Call the hospital in Iqaluit &amp; press 2 for English. \\\n",
    "Experience an aboriginal language as 1st choice\"\n",
    "RT_tweet_2 = \"For how long, i might be in NJ then?RT @FoolishInApril: @blove402 Thursday Night the 13th of Dec.\"\n",
    "URL_tweet = \"Get ready for our Wednesday Drink Specials Wednesday - 3-8pm Have it your Way Margarita Day \\\n",
    "( Bar Brand Only)... http://t.co/ml806WRT\"\n",
    "\n",
    "test1 = parse_tweet(first_tweet, *regex_args)\n",
    "test2 = parse_tweet(RT_tweet_1, *regex_args)\n",
    "test3 = parse_tweet(RT_tweet_2, *regex_args)\n",
    "test4 = parse_tweet(URL_tweet, *regex_args)\n",
    "print test1\n",
    "print test2\n",
    "print test3\n",
    "print test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          1  [Gas, by, my, house, hit, $3.39, !, !, !, !, I...\n",
      "1         -1  [Iranian, general, says, Israel's, Iron, Dome,...\n",
      "2          1  [with, J, Davlar, 11th, ., Main, rivals, are, ...\n",
      "3         -1  [Talking, about, ACT's, &amp;&amp;, SAT's,, de...\n",
      "4         -1  [They, may, have, a, SuperBowl, in, Dallas,, b...\n"
     ]
    }
   ],
   "source": [
    "# ok, now that we have rough parsing, lets parse them all!\n",
    "\n",
    "df.text = df.text.apply(lambda x: parse_tweet(x,*regex_args))\n",
    "print df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training tweets:  5661\n",
      "size of testing tweets:  1888\n"
     ]
    }
   ],
   "source": [
    "# now that we have all the tweets parsed, we actually want to split into our training / testing sets. \n",
    "# This is because n-gram analysis (which comes next), should not be done on the testing data!  \n",
    "# The n-gram analysis should on be on training data.  \n",
    "\n",
    "# TODO try to implement n-gram analysis with cross validation, for now I'll use a hold-out testing set\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#Let's split up the labels from the training data\n",
    "\n",
    "X_all = df['text']\n",
    "y_all = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "        X_all, y_all, test_size=0.25)\n",
    "\n",
    "print \"size of training tweets: \", len(X_train)\n",
    "print \"size of testing tweets: \", len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  sentiment\n",
      "6273  [@Cavillafuertee, Cav, !, See, you, tomorrow, ...          1\n",
      "3822  [Jungle, Island, says, it, will, be, open, as,...          0\n",
      "6351  [@DAISIA__Vu, wellllll, friday, imma, be, with...          0\n",
      "307   [@rinithyme, He'll, be, the, Eli, Manning, of,...          1\n",
      "5817  [Tragedy, struck, and, collided, in, my, sport...         -1\n",
      "6273    [@Cavillafuertee, Cav, !, See, you, tomorrow, ...\n",
      "3822    [Jungle, Island, says, it, will, be, open, as,...\n",
      "6351    [@DAISIA__Vu, wellllll, friday, imma, be, with...\n",
      "307     [@rinithyme, He'll, be, the, Eli, Manning, of,...\n",
      "5817    [Tragedy, struck, and, collided, in, my, sport...\n",
      "5069                          [ha, !, //t, ., co/Xaw29WA]\n",
      "6700    [Wicket,, its, getting, worse, for, the, Afgha...\n",
      "2239    [Listen, in, Hour, 2, for, an, expansive, inte...\n",
      "4743    [Nicki, Miinaj, Talks, to, Robin, Roberts, on,...\n",
      "6935    [The, Brick$quad, is, the, Yankees, of, 8th, p...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# tricked you! we need to merge the labels and parsed tweets for doing our n-gram analysis.\n",
    "# This is because we will build n-gram models for each class, therefore we need to select only\n",
    "# those tweets that are positive / negative for the two n-gram tables.\n",
    "\n",
    "# Let's re-merge the labels into the training data order to do n-gram analysis\n",
    "XyN_gram = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "print XyN_gram.head()\n",
    "print XyN_gram.text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the gram: ('Gas', 'by', 'my')\n",
      "this is the gram: ('by', 'my', 'house')\n",
      "this is the gram: ('my', 'house', 'hit')\n",
      "this is the gram: ('house', 'hit', '$3.39')\n",
      "this is the gram: ('hit', '$3.39', '!')\n",
      "this is the gram: ('$3.39', '!', '!')\n",
      "this is the gram: ('!', '!', '!')\n",
      "this is the gram: ('!', '!', '!')\n",
      "this is the gram: ('!', '!', \"I'm\")\n",
      "this is the gram: ('!', \"I'm\", 'going')\n",
      "this is the gram: (\"I'm\", 'going', 'to')\n",
      "this is the gram: ('going', 'to', 'Chapel')\n",
      "this is the gram: ('to', 'Chapel', 'Hill')\n",
      "this is the gram: ('Chapel', 'Hill', 'on')\n",
      "this is the gram: ('Hill', 'on', 'Sat')\n",
      "this is the gram: ('on', 'Sat', '.')\n",
      "this is the gram: ('Gas', 'by')\n",
      "this is the gram: ('by', 'my')\n",
      "this is the gram: ('my', 'house')\n",
      "this is the gram: ('house', 'hit')\n",
      "this is the gram: ('hit', '$3.39')\n",
      "this is the gram: ('$3.39', '!')\n",
      "this is the gram: ('!', '!')\n",
      "this is the gram: ('!', '!')\n",
      "this is the gram: ('!', '!')\n",
      "this is the gram: ('!', \"I'm\")\n",
      "this is the gram: (\"I'm\", 'going')\n",
      "this is the gram: ('going', 'to')\n",
      "this is the gram: ('to', 'Chapel')\n",
      "this is the gram: ('Chapel', 'Hill')\n",
      "this is the gram: ('Hill', 'on')\n",
      "this is the gram: ('on', 'Sat')\n",
      "this is the gram: ('Sat', '.')\n",
      "this is the gram: ('Gas',)\n",
      "this is the gram: ('by',)\n",
      "this is the gram: ('my',)\n",
      "this is the gram: ('house',)\n",
      "this is the gram: ('hit',)\n",
      "this is the gram: ('$3.39',)\n",
      "this is the gram: ('!',)\n",
      "this is the gram: ('!',)\n",
      "this is the gram: ('!',)\n",
      "this is the gram: ('!',)\n",
      "this is the gram: (\"I'm\",)\n",
      "this is the gram: ('going',)\n",
      "this is the gram: ('to',)\n",
      "this is the gram: ('Chapel',)\n",
      "this is the gram: ('Hill',)\n",
      "this is the gram: ('on',)\n",
      "this is the gram: ('Sat',)\n",
      "this is the gram: ('.',)\n",
      "{('.',): 1, (\"I'm\",): 1, ('Hill',): 1, ('!',): 4, ('on',): 1, ('my',): 1, ('$3.39',): 1, ('by',): 1, ('Sat',): 1, ('house',): 1, ('hit',): 1, ('Chapel',): 1, ('to',): 1, ('Gas',): 1, ('going',): 1}\n",
      " \n",
      "{('by', 'my'): 1, ('!', '!'): 3, ('!', \"I'm\"): 1, ('Hill', 'on'): 1, ('going', 'to'): 1, ('my', 'house'): 1, ('Sat', '.'): 1, ('to', 'Chapel'): 1, ('$3.39', '!'): 1, ('house', 'hit'): 1, ('Gas', 'by'): 1, ('hit', '$3.39'): 1, ('Chapel', 'Hill'): 1, (\"I'm\", 'going'): 1, ('on', 'Sat'): 1}\n",
      " \n",
      "{('my', 'house', 'hit'): 1, (\"I'm\", 'going', 'to'): 1, ('Gas', 'by', 'my'): 1, ('on', 'Sat', '.'): 1, ('!', '!', \"I'm\"): 1, ('house', 'hit', '$3.39'): 1, ('!', \"I'm\", 'going'): 1, ('going', 'to', 'Chapel'): 1, ('!', '!', '!'): 2, ('Chapel', 'Hill', 'on'): 1, ('hit', '$3.39', '!'): 1, ('Hill', 'on', 'Sat'): 1, ('to', 'Chapel', 'Hill'): 1, ('$3.39', '!', '!'): 1, ('by', 'my', 'house'): 1}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Let's start by developing a function that will take a parsed tweet and output grams of any size\n",
    "\n",
    "uni_gram_map = {}\n",
    "bi_gram_map = {}\n",
    "tri_gram_map = {}\n",
    "\n",
    "def nGram_counter (parsed_tweet, distance_to_cover, gram_map):\n",
    "    for_loop_range = range(len(parsed_tweet) - distance_to_cover)    \n",
    "    for i in for_loop_range:\n",
    "        gram = tuple(parsed_tweet[i:i+distance_to_cover])\n",
    "        print \"this is the gram:\",gram\n",
    "        if gram in gram_map:\n",
    "            gram_map[gram] += 1\n",
    "        else:\n",
    "            gram_map[gram] = 1\n",
    "\n",
    "\n",
    "            \n",
    "nGram_counter(test1, 3, tri_gram_map)\n",
    "nGram_counter(test1, 2, bi_gram_map)\n",
    "nGram_counter(test1, 1, uni_gram_map)\n",
    "\n",
    "#Our output should be a dictionaries of all possible tri-grams, bi-grams and unigrams of the tweet\n",
    "#\"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\"\n",
    "\n",
    "# if a particular gram exists more than once in a tweet, the counter should have incremented.  We see an example of this\n",
    "# with the token \"!!!!\" which is parsed into \"!!\" 3 times. and \"!!!\" twice. (it overlaps).\n",
    "\n",
    "print uni_gram_map\n",
    "print \" \"\n",
    "print bi_gram_map\n",
    "print \" \"\n",
    "print tri_gram_map\n",
    "print \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  sentiment\n",
      "6273  [@Cavillafuertee, Cav, !, See, you, tomorrow, ...          1\n",
      "307   [@rinithyme, He'll, be, the, Eli, Manning, of,...          1\n",
      "2239  [Listen, in, Hour, 2, for, an, expansive, inte...          1\n",
      "2628  [Well,, I, haven't, done, any, homework, in, t...          1\n",
      "616   [Celebrity, Juice, is, the, highlight, of, my,...          1\n",
      "6882  [@tomhanks, Youve, done, Bob's, Great,, The, P...          1\n",
      "1681  [@lovinjakemore, You, bet, !, And, @chuckonthe...          1\n",
      "4766  [Nicki, Minaj, flashes, a, nipple, on, Good, M...          1\n",
      "5078  [@laurenbuckenham, guess, what, im, working, i...          1\n",
      "943   [@JoeTribe_2012, runner, on, 2nd, no, outs,, d...          1\n",
      "the type on 'text' is  <class 'pandas.core.series.Series'>\n",
      "6273    [@Cavillafuertee, Cav, !, See, you, tomorrow, ...\n",
      "307     [@rinithyme, He'll, be, the, Eli, Manning, of,...\n",
      "2239    [Listen, in, Hour, 2, for, an, expansive, inte...\n",
      "2628    [Well,, I, haven't, done, any, homework, in, t...\n",
      "616     [Celebrity, Juice, is, the, highlight, of, my,...\n",
      "6882    [@tomhanks, Youve, done, Bob's, Great,, The, P...\n",
      "1681    [@lovinjakemore, You, bet, !, And, @chuckonthe...\n",
      "4766    [Nicki, Minaj, flashes, a, nipple, on, Good, M...\n",
      "5078    [@laurenbuckenham, guess, what, im, working, i...\n",
      "943     [@JoeTribe_2012, runner, on, 2nd, no, outs,, d...\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "(\"'NoneType' object is not callable\", u'occurred at index text')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-55707ddc328c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mpos_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpos_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#pos_tweets.apply(nGram_counter(pos_tweets.text, 3, tri_gram_map))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   3970\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3972\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3974\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4064\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4065\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4066\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: (\"'NoneType' object is not callable\", u'occurred at index text')"
     ]
    }
   ],
   "source": [
    "#let's now apply our n-gram counter to all the tweets of a certain class.\n",
    "# Let's make the positive n_gram map, on the training data.\n",
    "\n",
    "def print_tweet(text):\n",
    "    print \"the type on 'text' is \",type(text)\n",
    "    print text\n",
    "\n",
    "pos_tweets = XyN_gram[XyN_gram.sentiment == 1][:10]\n",
    "print pos_tweets\n",
    "pos_tweets.apply(print_tweet(pos_tweets.text))\n",
    "\n",
    "#pos_tweets.apply(nGram_counter(pos_tweets.text, 3, tri_gram_map))\n",
    "#print tri_gram_map\n",
    "\n",
    "\n",
    "#XyN_gram[XyN_gram.sentiment == 1].apply(nGram_counter(XyN_gram.text, 3, tri_gram_map))\n",
    "#print tri_gram_map\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
