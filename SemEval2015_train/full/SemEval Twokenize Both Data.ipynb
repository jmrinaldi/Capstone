{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOP Dataset has 13871 rows, 21 columns\n",
      "SEm Eval Dataset has 9665 rows, 4 columns\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "data_gop = pd.read_csv('/Users/Amar/PycharmProjects/MLND_projects/Capstone/data/first-GOP-debate/Sentiment.csv')\n",
    "data_semEval = pd.read_csv(\"downloaded2.tsv\", sep = '\\t')\n",
    "print \"GOP Dataset has {} rows, {} columns\".format(*data_gop.shape)\n",
    "print \"SEm Eval Dataset has {} rows, {} columns\".format(*data_semEval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' id', 0), ('candidate', 1), ('candidate_confidence', 2), ('relevant_yn', 3), ('relevant_yn_confidence', 4), ('sentiment', 5), ('sentiment_confidence', 6), ('subject_matter', 7), ('subject_matter_confidence', 8), ('candidate_gold', 9), ('name', 10), ('relevant_yn_gold', 11), ('retweet_count', 12), ('sentiment_gold', 13), ('subject_matter_gold', 14), ('text', 15), ('tweet_coord', 16), ('tweet_created', 17), ('tweet_id', 18), ('tweet_location', 19), ('user_timezone', 20)]\n"
     ]
    }
   ],
   "source": [
    "#A lot of information we really aren't interested in, so take a look at the columns with their index.\n",
    "header_index = [(i,z) for z,i in enumerate(data_gop.columns.view())]\n",
    "print header_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment                                               text\n",
      "0   Neutral  RT @NancyLeeGrahn: How did everyone feel about...\n",
      "1  Positive  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
      "2   Neutral  Re-SubmissionT @TJMShow: No mention of Tamir R...\n",
      "3  Positive  RT @RobGeorge: That Carly Fiorina is trending ...\n",
      "4  Positive  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
      "  sentiment                                               text\n",
      "0  positive  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1  negative  Iranian general says Israel's Iron Dome can't ...\n",
      "2  positive  with J Davlar 11th. Main rivals are team Polan...\n",
      "3  negative  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "4  negative  They may have a SuperBowl in Dallas, but Dalla...\n"
     ]
    }
   ],
   "source": [
    "#Now we can drop the ones we won't be using.  Keeping ID-0, sentiment-5, sentiment_confidence-6, text-15.\n",
    "df_gop = data_gop.drop(data_gop.columns[[0,1,2,3,4,6,7,8,9,10,11,12,13,14,16,17,18,19,20]], axis=1) #probably should keep sentiment confidance\n",
    "df_semEval = data_semEval.drop(data_semEval.columns[[0,1]], axis=1)\n",
    "\n",
    "#let's also drop rows that aren't available for semEval\n",
    "df_semEval = df_semEval[df_semEval.text != \"Not Available\"]\n",
    "df_semEval = df_semEval.reset_index(drop=True) #reset the index after dropping the above rows\n",
    "\n",
    "print df_gop.head()\n",
    "print df_semEval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gop tweets \n",
      "\n",
      "    sentiment                                               text\n",
      "0           0  RT @NancyLeeGrahn: How did everyone feel about...\n",
      "1           1  RT @ScottWalker: Didn't catch the full #GOPdeb...\n",
      "2           0  Re-SubmissionT @TJMShow: No mention of Tamir R...\n",
      "3           1  RT @RobGeorge: That Carly Fiorina is trending ...\n",
      "4           1  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...\n",
      "5           1  RT @GregAbbott_TX: @TedCruz: \"On my first day ...\n",
      "6          -1  RT @warriorwoman91: I liked her and was happy ...\n",
      "7           0  Going on #MSNBC Live with @ThomasARoberts arou...\n",
      "8          -1  Deer in the headlights RT @lizzwinstead: Ben C...\n",
      "9          -1  RT @NancyOsborne180: Last night's debate prove...\n",
      "10         -1  @JGreenDC @realDonaldTrump In all fairness #Bi...\n",
      "11          1  RT @WayneDupreeShow: Just woke up to tweet thi...\n",
      "12         -1  Me reading my family's comments about how grea...\n",
      "13          0  RT @ArcticFox2016: RT @AllenWestRepub \"Dear @J...\n",
      "14          1  RT @pattonoswalt: I loved Scott Walker as Mark...\n",
      "15         -1  Hey @ChrisChristie exploiting the tragedy of 9...\n",
      "16         -1  RT @CarolCNN: #DonaldTrump under fire for comm...\n",
      "17         -1  RT @johncardillo: Guess who had most speaking ...\n",
      "18         -1  reason comment is funny 'in case you're ignora...\n",
      "19         -1  RT @PamelaGeller: Huckabee: Paying for transge...\n",
      "semEval tweets \n",
      "\n",
      "    sentiment                                               text\n",
      "0           1  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1          -1  Iranian general says Israel's Iron Dome can't ...\n",
      "2           1  with J Davlar 11th. Main rivals are team Polan...\n",
      "3          -1  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "4          -1  They may have a SuperBowl in Dallas, but Dalla...\n",
      "5           0  Im bringing the monster load of candy tomorrow...\n",
      "6           0  Apple software, retail chiefs out in overhaul:...\n",
      "7           1  @oluoch @victor_otti @kunjand I just watched i...\n",
      "8           0  #Livewire Nadal confirmed for Mexican Open in ...\n",
      "9           1  @MsSheLahY I didnt want to just pop up... but ...\n",
      "10          0  @Alyoup005 @addicted2haley hmmmm  November is ...\n",
      "11          0  #Iran US delisting MKO from global terrorists ...\n",
      "12          1  Good Morning Becky ! Thursday is going to be F...\n",
      "13          0  Expect light-moderate rains over E. Visayas; C...\n",
      "14          1  One ticket left for the @49ers game tomorrow! ...\n",
      "15         -1  AFC away fans on Saturday. All this stuff abou...\n",
      "16         -1  Why is it so hard to find the @TVGuideMagazine...\n",
      "17          0  Game 1 of the NLCS and a rematch of the NFC Ch...\n",
      "18          0  @TrevorJavier the heat game may cost alot more...\n",
      "19          1  Never start working on your dreams and goals t...\n"
     ]
    }
   ],
   "source": [
    "#Next we need to re-write the neutral / objective labels to all be neutral.  The organizers kept this distinction\n",
    "#for other tasks, but for this task, it's considered the same.\n",
    "# so, let's re-write all objective ->neutral, and all neutral-OR-objective --> neutral.\n",
    "\n",
    "#Since we probably will want our labels numeric (some classifiers may not like 3-way text labels),\n",
    "#we can do that all now.\n",
    "\n",
    "df_gop = df_gop.apply(lambda x: x.replace(['Positive', 'Negative', 'Neutral'] \n",
    "                                  , [1, -1,0]) ,1)\n",
    "print \"gop tweets \\n\"\n",
    "print df_gop[:20]\n",
    "\n",
    "df_semEval = df_semEval.apply(lambda x: x.replace(['positive', 'negative', 'neutral', 'objective', 'objective-OR-neutral']\n",
    "                                  , [1, -1,0,0,0]) ,1)\n",
    "print \"semEval tweets \\n\"\n",
    "print df_semEval[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's combine our datasets now that they are both ready and in the same format\n",
    "df = pd.concat([df_semEval, df_gop], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is : 21420\n",
      "There are 5056 positive tweets or 0.2360410831%\n",
      "There are 9559 Negative tweets or 0.446265172736%\n",
      "There are 6805 Neutral tweets or 0.317693744164%\n"
     ]
    }
   ],
   "source": [
    "#Let's take a look at our class distribution\n",
    "total_tweets = len(df)\n",
    "positive_tweets = sum(df.sentiment == 1)\n",
    "negative_tweets = sum(df.sentiment == -1)\n",
    "neutral_tweets = sum(df.sentiment == 0)\n",
    "\n",
    "print \"The total number of samples is : {}\".format(len(df.sentiment))\n",
    "print \"There are {} positive tweets or {}%\".format \\\n",
    "(positive_tweets, positive_tweets/float(total_tweets) )\n",
    "print \"There are {} Negative tweets or {}%\".format \\\n",
    "(negative_tweets, negative_tweets / float(total_tweets))\n",
    "print \"There are {} Neutral tweets or {}%\".format \\\n",
    "(neutral_tweets, neutral_tweets/ float(total_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                               text\n",
      "0          1  Gas by my house hit $3.39!!!! I'm going to Cha...\n",
      "1          0  Iranian general says Israel's Iron Dome can't ...\n",
      "2          1  with J Davlar 11th. Main rivals are team Polan...\n",
      "3          0  Talking about ACT's &amp;&amp; SAT's, deciding...\n",
      "4          0  They may have a SuperBowl in Dallas, but Dalla...\n"
     ]
    }
   ],
   "source": [
    "# Ok, for now, let's build a positive classifier:\n",
    "df = df.apply(lambda x: x.replace(-1, 0))\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gas', 'by', 'my', 'house', 'hit', '$3.39', '!!!!', \"I'm\", 'going', 'to', 'Chapel', 'Hill', 'on', 'Sat', '.', ':)']\n",
      "['Cool', '#cdnpoli', 'RT', '@angelpike', ':', 'Call', 'the', 'hospital', 'in', 'Iqaluit', '&', 'press', '2', 'for', 'English', '.', 'Experience', 'an', 'aboriginal', 'language', 'as', '1st', 'choice']\n",
      "['For', 'how', 'long', ',', 'i', 'might', 'be', 'in', 'NJ', 'then', '?', 'RT', '@FoolishInApril', ':', '@blove402', 'Thursday', 'Night', 'the', '13th', 'of', 'Dec', '.']\n",
      "['Get', 'ready', 'for', 'our', 'Wednesday', 'Drink', 'Specials', 'Wednesday', '-', '3-8pm', 'Have', 'it', 'your', 'Way', 'Margarita', 'Day', '(', 'Bar', 'Brand', 'Only', ')', '...', 'http://t.co/ml806WRT']\n"
     ]
    }
   ],
   "source": [
    "# ok let's parse the tweets use the ARK tokenizer from CMU.\n",
    "import twokenize as tw\n",
    "\n",
    "first_tweet = \"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\"\n",
    "RT_tweet_1 = \"Cool #cdnpoli RT@angelpike: Call the hospital in Iqaluit &amp; press 2 for English. \\\n",
    "Experience an aboriginal language as 1st choice\"\n",
    "RT_tweet_2 = \"For how long, i might be in NJ then?RT @FoolishInApril: @blove402 Thursday Night the 13th of Dec.\"\n",
    "URL_tweet = \"Get ready for our Wednesday Drink Specials Wednesday - 3-8pm Have it your Way Margarita Day \\\n",
    "( Bar Brand Only)... http://t.co/ml806WRT\"\n",
    "\n",
    "test_tweets = [first_tweet, RT_tweet_1, RT_tweet_2, URL_tweet]\n",
    "\n",
    "for tweet in test_tweets:\n",
    "    print tw.tokenizeRawTweetText(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ok, now that we have rough parsing, lets parse them all!\n",
    "df.text = df.text.apply(lambda x: parse_tweet(x,*regex_args))\n",
    "print df.head()\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop some tweets that got parsed to zero\n",
    "df = df[df['text'].map(len) >= 1]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now that we have all the tweets parsed, we actually want to split into our training / testing sets. \n",
    "# This is because n-gram analysis (which comes next), should not be done on the testing data!  \n",
    "# The n-gram analysis should on be on training data.  \n",
    "\n",
    "# TODO try to implement n-gram analysis with cross validation, for now I'll use a hold-out testing set\n",
    "from sklearn import cross_validation\n",
    "\n",
    "#Let's split up the labels from the training data\n",
    "\n",
    "X_all = df['text']\n",
    "y_all = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "        X_all, y_all, test_size=0.25, stratify = y_all)\n",
    "\n",
    "print \"size of training tweets: \", len(X_train)\n",
    "print \"size of testing tweets: \", len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tricked you! we need to merge the labels and parsed tweets for doing our n-gram analysis.\n",
    "# This is because we will build n-gram models for each class, therefore we need to select only\n",
    "# those tweets that are positive / negative for the two n-gram tables.\n",
    "\n",
    "# Let's re-merge the labels into the training data order to do n-gram analysis\n",
    "XyN_gram = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "print XyN_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's start by developing a function that will take a parsed tweet and output grams of any size\n",
    "\n",
    "uni_gram_map = {}\n",
    "bi_gram_map = {}\n",
    "tri_gram_map = {}\n",
    "\n",
    "def nGram_counter (parsed_tweet, distance_to_cover, gram_map):\n",
    "    for_loop_range = range(len(parsed_tweet) - distance_to_cover)    \n",
    "    for i in for_loop_range:\n",
    "        gram = tuple(parsed_tweet[i:i+distance_to_cover])\n",
    "        if gram in gram_map:\n",
    "            gram_map[gram] += 1\n",
    "        else:\n",
    "            gram_map[gram] = 1\n",
    "\n",
    "nGram_counter(test1, 3, tri_gram_map)\n",
    "nGram_counter(test1, 2, bi_gram_map)\n",
    "nGram_counter(test1, 1, uni_gram_map)\n",
    "\n",
    "#Our output should be a dictionaries of all possible tri-grams, bi-grams and unigrams of the tweet\n",
    "#\"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\"\n",
    "\n",
    "# if a particular gram exists more than once in a tweet, the counter should have incremented.  We see an example of this\n",
    "# with the token \"!!!!\" which is parsed into \"!!\" 3 times. and \"!!!\" twice. (it overlaps).\n",
    "\n",
    "\n",
    "# check our output.\n",
    "print uni_gram_map\n",
    "print \" \"\n",
    "print bi_gram_map\n",
    "print \" \"\n",
    "print tri_gram_map\n",
    "print \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's now apply our n-gram counter to all the tweets of a certain class.\n",
    "# Let's make the positive n_gram map, on the training data.\n",
    "\n",
    "#for now I will merge all grams into a single map, maybe harder for stats later, but easier for coding now\n",
    "\n",
    "#setup n-gram maps.\n",
    "pos_uni_gram_map ={}\n",
    "pos_bi_gram_map = {}\n",
    "pos_tri_gram_map = {}\n",
    "\n",
    "pos_tweets = XyN_gram[XyN_gram.sentiment == 1]\n",
    "\n",
    "pos_tweets.apply(lambda x: nGram_counter(x.text, 1, pos_uni_gram_map), 1)\n",
    "pos_tweets.apply(lambda x: nGram_counter(x.text, 2, pos_bi_gram_map), 1)\n",
    "pos_tweets.apply(lambda x: nGram_counter(x.text, 3, pos_tri_gram_map), 1)\n",
    "print \"Total Unigrams for Positive Tweets : {}\".format(len(pos_uni_gram_map))\n",
    "print \n",
    "print \"Total Bi-grams for Positive Tweets: {}\".format(len(pos_bi_gram_map))\n",
    "print\n",
    "print \"Total Tri-grams for Positive Tweets: {}\".format(len(pos_tri_gram_map))\n",
    "print\n",
    "print \"Most popular Positive Uni-grams : {}\" \\\n",
    ".format(sorted(pos_uni_gram_map.items(), key=lambda x: x[1], reverse = True)[:30])\n",
    "print\n",
    "print \"Most Popular Positive  Bi-gams : {}\" \\\n",
    ".format(sorted(pos_bi_gram_map.items(), key = lambda x: x[1], reverse = True)[:30])\n",
    "print\n",
    "print \"Most popular Positive Tri-grams : {}\" \\\n",
    ".format(sorted(pos_tri_gram_map.items(), key=lambda x: x[1], reverse = True)[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ok, lets use these gram maps to create some features finally.\n",
    "so what we want to do is :\n",
    "\n",
    "take each tweet.text and calculate the probability of that tweet existing as a positive tweet.  \n",
    "we can use this feature to construct our first classifier, for positive tweets.\n",
    "let's start by defining a function that calculates the probability of a tweet.  \n",
    "I will need to include smoothing, normalization and worry about over / underflow.\n",
    "actually the very first step is to transform our maps into maximum likliehood probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# maximum likliehood probabilities for positive grams.\n",
    "# we will calculate maximum likliehood with smoothing, will use simple k-smoothing, with k = 1\n",
    "\n",
    "\n",
    "def calculate_maximum_likliehood (gram_map, k_smoothing = 1, Prior_map = None):\n",
    "    MLE_estimates = {}\n",
    "    total_unique_grams = len(gram_map) # this is V for smoothing \n",
    "    total_gram_count = sum(gram_map.values())\n",
    "    \n",
    "    if Prior_map != None:\n",
    "        total_prior_gram_count = sum(Prior_map.values()) # also V for smoothing on conditioned grams\n",
    "    \n",
    "    #figure out what kind of gram-map we have\n",
    "    keys = gram_map.keys()\n",
    "    if len(keys[0]) == 1: # we have unigrams\n",
    "        for key in keys:\n",
    "            MLE_estimates[key] = (gram_map[key]+ k_smoothing) / \\\n",
    "            float(total_unique_grams + k_smoothing * total_gram_count)\n",
    "            # above will give MLE with smoothing = 1\n",
    "                \n",
    "    elif len(keys[0]) == 2: # This means we want to condition on previous uni gram\n",
    "        for key in keys:\n",
    "            MLE_estimates[key] = (gram_map[key] + k_smoothing) / \\\n",
    "            float(Prior_map[key[0],] + k_smoothing * total_prior_gram_count)\n",
    "    else: #should be 3 size, so condition on previous bi-gram\n",
    "        for key in keys:\n",
    "            MLE_estimates[key] = (gram_map[key] + k_smoothing) / \\\n",
    "            float(Prior_map[key[:2]] + k_smoothing * total_prior_gram_count)\n",
    "            \n",
    "\n",
    "    return MLE_estimates\n",
    "\n",
    "MLE_pos_uni_gram = calculate_maximum_likliehood(pos_uni_gram_map , 1)\n",
    "MLE_pos_bi_gram = calculate_maximum_likliehood(pos_bi_gram_map, 1, Prior_map=pos_uni_gram_map)\n",
    "MLE_pos_tri_gram = calculate_maximum_likliehood(pos_tri_gram_map, 1, Prior_map=pos_bi_gram_map)\n",
    "\n",
    "## sanity checks\n",
    "print len(MLE_pos_uni_gram) == len(pos_uni_gram_map)\n",
    "print len(MLE_pos_bi_gram) == len(pos_bi_gram_map)\n",
    "print len(MLE_pos_tri_gram) == len(pos_tri_gram_map)\n",
    "\n",
    "# should look reasonble?\n",
    "print MLE_pos_bi_gram.values()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ok, now we have MLE for all the training data.  This is n-gram analysis on the positive data.\n",
    "NExt we need to reparse all the tweets, looking up their values in the MLE_pos gram maps.\n",
    "Take log probabilities of everything If a gram doesn't exist in the correct place, then we'll use smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def v_plus_n(grams):\n",
    "    total_unique_grams = len(grams) # this is V for smoothing \n",
    "    total_gram_count = sum(grams.values()) #this is N\n",
    "    return float(total_unique_grams + total_gram_count)\n",
    "\n",
    "\n",
    "def positive_probability_calculator (parsed_tweet, gram_size):\n",
    "    \n",
    "    if len(parsed_tweet) <1:  #this will catch any empty tweets I missed earlier.\n",
    "        return \"NaN\"\n",
    "    \n",
    "    # access the gram maps we've calculated before\n",
    "    global MLE_pos_uni_gram\n",
    "    global MLE_pos_bi_gram\n",
    "    global MLE_pos_tri_gram\n",
    "    \n",
    "    global pos_uni_gram_map\n",
    "    global pos_bi_gram_map\n",
    "    \n",
    "    uni_VplusN = v_plus_n(pos_uni_gram_map) # will use these values in smoothing\n",
    "    bi_VplusN = v_plus_n(pos_bi_gram_map)\n",
    "    tri_VplusN = v_plus_n(pos_tri_gram_map)\n",
    "        \n",
    "    # gram_map should correspond to gram_size i.E bi-grams, or tri-grams etc.\n",
    "    loop_range = range(len(parsed_tweet) - gram_size)\n",
    "    prob = 0\n",
    "    \n",
    "    if gram_size == 1: #unigrams\n",
    "        for i in loop_range:\n",
    "            gram = tuple(parsed_tweet[i:i+gram_size])\n",
    "            \n",
    "            if gram in MLE_pos_uni_gram: #look up the probability value we've already calculated\n",
    "                prob += math.log(MLE_pos_uni_gram[gram])\n",
    "            else:  #it's unseen so create a new probability with k-smoothing\n",
    "                #pass # penalize it with nothing\n",
    "                prob += math.log( 1.0 / uni_VplusN )  \n",
    "    \n",
    "    if gram_size == 2: #bi-grams\n",
    "        for i in loop_range:\n",
    "            gram = tuple(parsed_tweet[i:i+gram_size])\n",
    "            \n",
    "            if gram in MLE_pos_bi_gram:\n",
    "                prob += math.log(MLE_pos_bi_gram[gram])  #look up probability we've calculated\n",
    "            \n",
    "            else:  #condition the unseen bi-gram on the seen unigram.\n",
    "                #pass\n",
    "                if (gram[0],) in pos_uni_gram_map:\n",
    "                    prob += math.log( 1.0 / (pos_uni_gram_map[gram[0],] + len(pos_uni_gram_map)))  \n",
    "                    \n",
    "                    # so if gram = ('this','cat'), and we have never seen that before.  we are\n",
    "                    # getting a probability that is: 1 / count('this') + count(unique_single grams)\n",
    "                    #obviously close to zero.  ....\n",
    "                else: #then even the first part of this unseen bigram is not the unigram database, just do V+N\n",
    "                    prob += math.log(1.0 / bi_VplusN)\n",
    "    \n",
    "    if gram_size == 3: #tri-grams\n",
    "        for i in loop_range:\n",
    "            gram = tuple(parsed_tweet[i:i+gram_size])\n",
    "            \n",
    "            if gram in MLE_pos_tri_gram:\n",
    "                prob += math.log(MLE_pos_tri_gram[gram]) # look up prob we've already calculated\n",
    "            \n",
    "            else:\n",
    "                #pass\n",
    "                if gram[:2] in pos_bi_gram_map:\n",
    "                    prob += math.log( 1.0 / (pos_bi_gram_map[gram[:2]] + len(pos_bi_gram_map)))\n",
    "                else:\n",
    "                    prob += math.log(1.0 / tri_VplusN)\n",
    "                             \n",
    "    probability = math.exp(prob) / len(parsed_tweet) # normalize by the number of grams in the tweet.\n",
    "    return probability\n",
    "   \n",
    "\n",
    "test_tweet = ['Gas', 'by', 'my', 'house', 'hit', '$3.39', '!', '!', '!', '!', \"I'm\", 'going', 'to', 'Chapel', 'Hill', 'on', 'Sat', '.', ':)']\n",
    "\n",
    "print positive_probability_calculator(test_tweet,1)\n",
    "print positive_probability_calculator(test_tweet,2)\n",
    "print positive_probability_calculator(test_tweet,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "now we want to make features using the probability calculator!! time to finally get positive probability features for all our tweets.  both training and testing need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_trainy = pd.DataFrame(X_train)  #have to convert the Series into a dataframe, in order to add columns\n",
    "X_trainy['POS-uni'] = X_trainy.text.apply(lambda x: positive_probability_calculator(x, 1),1)\n",
    "X_trainy['POS-bi'] = X_trainy.text.apply(lambda x: positive_probability_calculator(x,2),1)\n",
    "X_trainy['POS-tri'] = X_trainy.text.apply(lambda x: positive_probability_calculator(x,3),1)\n",
    "print X_trainy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_testy = pd.DataFrame(X_test) #have to convert the Series into a dataframe, in order to add columns\n",
    "X_testy['POS-uni'] = X_testy.text.apply(lambda x: positive_probability_calculator(x, 1), 1)\n",
    "X_testy['POS-bi'] = X_testy.text.apply(lambda x: positive_probability_calculator(x,2),1)\n",
    "X_testy['POS-tri'] = X_testy.text.apply(lambda x: positive_probability_calculator(x,3),1)\n",
    "print X_testy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we can now make a classifier with these features.  This classifier will predict positive labels.  Let's try a few classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First let's drop the text tweets, they aren't helpful in actual classification\n",
    "X_trainy = X_trainy.drop(X_trainy.columns[0], axis =1)\n",
    "print X_trainy.head()\n",
    "X_testy = X_testy.drop(X_testy.columns[0], axis =1)\n",
    "print X_testy.head()\n",
    "\n",
    "#should be no reason to scale data, because we've normalized it all, it's all probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def f1_score_wrap (y_actual, y_predict):\n",
    "    return f1_score(y_actual, y_predict)\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "def basic(clf):\n",
    "    clf.fit(X_trainy, y_train)\n",
    "\n",
    "    x_pred = clf.predict(X_trainy)\n",
    "    F1_train = f1_score_wrap(y_train, x_pred)\n",
    "    train_conf = confusion_matrix(y_train, x_pred)\n",
    "    \n",
    "    print \"training F1:\", F1_train\n",
    "    print\n",
    "    print \"training confusion:\\n\", train_conf\n",
    "    print\n",
    "    \n",
    "    y_pred = clf.predict(X_testy)\n",
    "    F1_score = f1_score_wrap(y_test, y_pred)\n",
    "    conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print \"testing F1:\", F1_score\n",
    "    print\n",
    "    print \"confusion for testing\\n\", conf\n",
    "    \n",
    "basic(clf)\n",
    "print X_testy.shape\n",
    "print X_trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "basic(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "basic(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "basic(gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "basic(clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
